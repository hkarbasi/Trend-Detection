{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.01493,
     "end_time": "2019-05-20T15:41:42.911489",
     "exception": false,
     "start_time": "2019-05-20T15:41:42.896559",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_cores = 14\n",
    "mem = 700000\n",
    "config = \"configs.config_Reddit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:08.370500Z",
     "start_time": "2019-05-20T15:39:08.367187Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 0.013653,
     "end_time": "2019-05-20T15:41:42.934438",
     "exception": false,
     "start_time": "2019-05-20T15:41:42.920785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "if 'config' not in locals():\n",
    "    config = 'configs.config_SE_test_local'\n",
    "#     config = 'configs.config_Reddit_test_local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:14.491159Z",
     "start_time": "2019-05-20T15:39:08.726403Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 8.035903,
     "end_time": "2019-05-20T15:41:50.979287",
     "exception": false,
     "start_time": "2019-05-20T15:41:42.943384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file is set to configs.config_Reddit\n",
      "num_cores is set to 14\n",
      "mem is set to 700000\n"
     ]
    }
   ],
   "source": [
    "### initialization ###\n",
    "\n",
    "from _imports import *\n",
    "# from _utils import *\n",
    "\n",
    "print('config file is set to {}'.format(config))\n",
    "\n",
    "util=importlib.import_module('_utils')\n",
    "importlib.reload(util)\n",
    "\n",
    "c=importlib.import_module(config)\n",
    "importlib.reload(c)\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# param_setup(sys.argv[1:], c)\n",
    "util.param_setup_ipython(globals(), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:15.229930Z",
     "start_time": "2019-05-20T15:39:14.493993Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 46.377789,
     "end_time": "2019-05-20T15:42:37.366653",
     "exception": false,
     "start_time": "2019-05-20T15:41:50.988864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Number of topics = 62'\n",
      "'Number of docs = 2225657'\n"
     ]
    }
   ],
   "source": [
    "### loading optimal model db and tags file ###\n",
    "\n",
    "if c.tags is not None:\n",
    "    df_tags = pd.read_csv('{}{}_0_tags.csv'.format(c.directory['save'], c.project_name))\n",
    "    c.tags_dict = dict(zip(df_tags['key'], df_tags['val']))\n",
    "\n",
    "dbfile = open('{}{}_db_optimal_model-{}-{}.pickle'.format(c.directory['save'],\n",
    "                                                          c.project_name,\n",
    "                                                          c.optimal_LDA_iteration_threshold,\n",
    "                                                          c.num_topics\n",
    "                                                         ), 'rb') \n",
    "db=pickle.load(dbfile)                      \n",
    "dbfile.close()\n",
    "\n",
    "optimal_model=db['model']\n",
    "optimal_model_corpus=db['optimal_model_corpus']\n",
    "c.num_topics=db['num_topics']\n",
    "df_text=db['df_text']\n",
    "data_lemmatized=df_text['txt_lemmatized']\n",
    "\n",
    "pprint('Number of topics = {}'.format(c.num_topics))\n",
    "pprint('Number of docs = {}'.format(len(data_lemmatized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:17.261853Z",
     "start_time": "2019-05-20T15:39:15.232459Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 76.144294,
     "end_time": "2019-05-20T15:43:53.522365",
     "exception": false,
     "start_time": "2019-05-20T15:42:37.378071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 14 partitions with 14 cores for str_to_list_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "      <th>Topic 21</th>\n",
       "      <th>Topic 22</th>\n",
       "      <th>Topic 23</th>\n",
       "      <th>Topic 24</th>\n",
       "      <th>Topic 25</th>\n",
       "      <th>Topic 26</th>\n",
       "      <th>Topic 27</th>\n",
       "      <th>Topic 28</th>\n",
       "      <th>Topic 29</th>\n",
       "      <th>Topic 30</th>\n",
       "      <th>Topic 31</th>\n",
       "      <th>Topic 32</th>\n",
       "      <th>Topic 33</th>\n",
       "      <th>Topic 34</th>\n",
       "      <th>Topic 35</th>\n",
       "      <th>Topic 36</th>\n",
       "      <th>Topic 37</th>\n",
       "      <th>Topic 38</th>\n",
       "      <th>Topic 39</th>\n",
       "      <th>Topic 40</th>\n",
       "      <th>Topic 41</th>\n",
       "      <th>Topic 42</th>\n",
       "      <th>Topic 43</th>\n",
       "      <th>Topic 44</th>\n",
       "      <th>Topic 45</th>\n",
       "      <th>Topic 46</th>\n",
       "      <th>Topic 47</th>\n",
       "      <th>Topic 48</th>\n",
       "      <th>Topic 49</th>\n",
       "      <th>Topic 50</th>\n",
       "      <th>Topic 51</th>\n",
       "      <th>Topic 52</th>\n",
       "      <th>Topic 53</th>\n",
       "      <th>Topic 54</th>\n",
       "      <th>Topic 55</th>\n",
       "      <th>Topic 56</th>\n",
       "      <th>Topic 57</th>\n",
       "      <th>Topic 58</th>\n",
       "      <th>Topic 59</th>\n",
       "      <th>Topic 60</th>\n",
       "      <th>Topic 61</th>\n",
       "      <th>Topic 62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>learn</td>\n",
       "      <td>gpu</td>\n",
       "      <td>pay</td>\n",
       "      <td>peopl</td>\n",
       "      <td>googl</td>\n",
       "      <td>energi</td>\n",
       "      <td>www</td>\n",
       "      <td>differ</td>\n",
       "      <td>data</td>\n",
       "      <td>eat</td>\n",
       "      <td>flight</td>\n",
       "      <td>time</td>\n",
       "      <td>day</td>\n",
       "      <td>word</td>\n",
       "      <td>data</td>\n",
       "      <td>wiki</td>\n",
       "      <td>war</td>\n",
       "      <td>distribut</td>\n",
       "      <td>temperatur</td>\n",
       "      <td>video</td>\n",
       "      <td>drug</td>\n",
       "      <td>news</td>\n",
       "      <td>game</td>\n",
       "      <td>pay</td>\n",
       "      <td>vote</td>\n",
       "      <td>white</td>\n",
       "      <td>car</td>\n",
       "      <td>research</td>\n",
       "      <td>school</td>\n",
       "      <td>peopl</td>\n",
       "      <td>work</td>\n",
       "      <td>peopl</td>\n",
       "      <td>phone</td>\n",
       "      <td>feel</td>\n",
       "      <td>imag</td>\n",
       "      <td>gun</td>\n",
       "      <td>kid</td>\n",
       "      <td>movi</td>\n",
       "      <td>citi</td>\n",
       "      <td>dog</td>\n",
       "      <td>number</td>\n",
       "      <td>read</td>\n",
       "      <td>cour</td>\n",
       "      <td>govern</td>\n",
       "      <td>comment</td>\n",
       "      <td>woman</td>\n",
       "      <td>fuck</td>\n",
       "      <td>make</td>\n",
       "      <td>model</td>\n",
       "      <td>project</td>\n",
       "      <td>game</td>\n",
       "      <td>problem</td>\n",
       "      <td>drink</td>\n",
       "      <td>data</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>data</td>\n",
       "      <td>imag</td>\n",
       "      <td>countri</td>\n",
       "      <td>data</td>\n",
       "      <td>peopl</td>\n",
       "      <td>compani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valu</td>\n",
       "      <td>paper</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>money</td>\n",
       "      <td>thing</td>\n",
       "      <td>page</td>\n",
       "      <td>water</td>\n",
       "      <td>org</td>\n",
       "      <td>group</td>\n",
       "      <td>sourc</td>\n",
       "      <td>food</td>\n",
       "      <td>plane</td>\n",
       "      <td>peopl</td>\n",
       "      <td>time</td>\n",
       "      <td>languag</td>\n",
       "      <td>python</td>\n",
       "      <td>index</td>\n",
       "      <td>militari</td>\n",
       "      <td>function</td>\n",
       "      <td>year</td>\n",
       "      <td>post</td>\n",
       "      <td>peopl</td>\n",
       "      <td>trump</td>\n",
       "      <td>win</td>\n",
       "      <td>tax</td>\n",
       "      <td>state</td>\n",
       "      <td>black</td>\n",
       "      <td>drive</td>\n",
       "      <td>ai</td>\n",
       "      <td>student</td>\n",
       "      <td>religion</td>\n",
       "      <td>job</td>\n",
       "      <td>countri</td>\n",
       "      <td>internet</td>\n",
       "      <td>time</td>\n",
       "      <td>train</td>\n",
       "      <td>peopl</td>\n",
       "      <td>child</td>\n",
       "      <td>show</td>\n",
       "      <td>live</td>\n",
       "      <td>back</td>\n",
       "      <td>data</td>\n",
       "      <td>someth</td>\n",
       "      <td>learn</td>\n",
       "      <td>peopl</td>\n",
       "      <td>reddit</td>\n",
       "      <td>man</td>\n",
       "      <td>peopl</td>\n",
       "      <td>point</td>\n",
       "      <td>data</td>\n",
       "      <td>work</td>\n",
       "      <td>play</td>\n",
       "      <td>time</td>\n",
       "      <td>buy</td>\n",
       "      <td>job</td>\n",
       "      <td>money</td>\n",
       "      <td>graph</td>\n",
       "      <td>link</td>\n",
       "      <td>american</td>\n",
       "      <td>question</td>\n",
       "      <td>make</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>column</td>\n",
       "      <td>model</td>\n",
       "      <td>run</td>\n",
       "      <td>hous</td>\n",
       "      <td>realli</td>\n",
       "      <td>site</td>\n",
       "      <td>power</td>\n",
       "      <td>html</td>\n",
       "      <td>thing</td>\n",
       "      <td>tool</td>\n",
       "      <td>fat</td>\n",
       "      <td>fli</td>\n",
       "      <td>thing</td>\n",
       "      <td>hour</td>\n",
       "      <td>text</td>\n",
       "      <td>r</td>\n",
       "      <td>visual</td>\n",
       "      <td>countri</td>\n",
       "      <td>valu</td>\n",
       "      <td>earth</td>\n",
       "      <td>realli</td>\n",
       "      <td>smoke</td>\n",
       "      <td>articl</td>\n",
       "      <td>play</td>\n",
       "      <td>money</td>\n",
       "      <td>elect</td>\n",
       "      <td>peopl</td>\n",
       "      <td>road</td>\n",
       "      <td>paper</td>\n",
       "      <td>colleg</td>\n",
       "      <td>muslim</td>\n",
       "      <td>peopl</td>\n",
       "      <td>high</td>\n",
       "      <td>appl</td>\n",
       "      <td>realli</td>\n",
       "      <td>layer</td>\n",
       "      <td>kill</td>\n",
       "      <td>parent</td>\n",
       "      <td>episod</td>\n",
       "      <td>state</td>\n",
       "      <td>hand</td>\n",
       "      <td>averag</td>\n",
       "      <td>good</td>\n",
       "      <td>machin learn</td>\n",
       "      <td>state</td>\n",
       "      <td>post</td>\n",
       "      <td>male</td>\n",
       "      <td>shit</td>\n",
       "      <td>fact</td>\n",
       "      <td>train</td>\n",
       "      <td>code</td>\n",
       "      <td>team</td>\n",
       "      <td>work</td>\n",
       "      <td>beer</td>\n",
       "      <td>work</td>\n",
       "      <td>valu</td>\n",
       "      <td>color</td>\n",
       "      <td>tri</td>\n",
       "      <td>europ</td>\n",
       "      <td>answer</td>\n",
       "      <td>person</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cluster</td>\n",
       "      <td>train</td>\n",
       "      <td>model</td>\n",
       "      <td>year</td>\n",
       "      <td>lot</td>\n",
       "      <td>user</td>\n",
       "      <td>build</td>\n",
       "      <td>pdf</td>\n",
       "      <td>correl</td>\n",
       "      <td>visual</td>\n",
       "      <td>calori</td>\n",
       "      <td>ship</td>\n",
       "      <td>happen</td>\n",
       "      <td>year</td>\n",
       "      <td>english</td>\n",
       "      <td>code</td>\n",
       "      <td>data</td>\n",
       "      <td>world</td>\n",
       "      <td>point</td>\n",
       "      <td>warm</td>\n",
       "      <td>interest</td>\n",
       "      <td>vaccin</td>\n",
       "      <td>sourc</td>\n",
       "      <td>move</td>\n",
       "      <td>cost</td>\n",
       "      <td>trump</td>\n",
       "      <td>race</td>\n",
       "      <td>driver</td>\n",
       "      <td>human</td>\n",
       "      <td>educ</td>\n",
       "      <td>christian</td>\n",
       "      <td>pay</td>\n",
       "      <td>popul</td>\n",
       "      <td>app</td>\n",
       "      <td>make</td>\n",
       "      <td>network</td>\n",
       "      <td>shoot</td>\n",
       "      <td>peopl</td>\n",
       "      <td>watch</td>\n",
       "      <td>area</td>\n",
       "      <td>guy</td>\n",
       "      <td>rate</td>\n",
       "      <td>start</td>\n",
       "      <td>book</td>\n",
       "      <td>law</td>\n",
       "      <td>subreddit</td>\n",
       "      <td>femal</td>\n",
       "      <td>make</td>\n",
       "      <td>argument</td>\n",
       "      <td>predict</td>\n",
       "      <td>interest</td>\n",
       "      <td>sport</td>\n",
       "      <td>thing</td>\n",
       "      <td>food</td>\n",
       "      <td>data scienc</td>\n",
       "      <td>currenc</td>\n",
       "      <td>line</td>\n",
       "      <td>index</td>\n",
       "      <td>world</td>\n",
       "      <td>inform</td>\n",
       "      <td>thing</td>\n",
       "      <td>busi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>comput</td>\n",
       "      <td>live</td>\n",
       "      <td>good</td>\n",
       "      <td>search</td>\n",
       "      <td>electr</td>\n",
       "      <td>jpg</td>\n",
       "      <td>peopl</td>\n",
       "      <td>www</td>\n",
       "      <td>weight</td>\n",
       "      <td>travel</td>\n",
       "      <td>chang</td>\n",
       "      <td>week</td>\n",
       "      <td>sentenc</td>\n",
       "      <td>languag</td>\n",
       "      <td>post</td>\n",
       "      <td>russia</td>\n",
       "      <td>probabl</td>\n",
       "      <td>climat</td>\n",
       "      <td>make</td>\n",
       "      <td>doctor</td>\n",
       "      <td>medium</td>\n",
       "      <td>number</td>\n",
       "      <td>spend</td>\n",
       "      <td>parti</td>\n",
       "      <td>racist</td>\n",
       "      <td>time</td>\n",
       "      <td>work</td>\n",
       "      <td>class</td>\n",
       "      <td>religi</td>\n",
       "      <td>make</td>\n",
       "      <td>world</td>\n",
       "      <td>netflix</td>\n",
       "      <td>good</td>\n",
       "      <td>input</td>\n",
       "      <td>crime</td>\n",
       "      <td>famili</td>\n",
       "      <td>good</td>\n",
       "      <td>peopl</td>\n",
       "      <td>wear</td>\n",
       "      <td>high</td>\n",
       "      <td>point</td>\n",
       "      <td>math</td>\n",
       "      <td>system</td>\n",
       "      <td>link</td>\n",
       "      <td>gender</td>\n",
       "      <td>guy</td>\n",
       "      <td>claim</td>\n",
       "      <td>featur</td>\n",
       "      <td>find</td>\n",
       "      <td>player</td>\n",
       "      <td>make</td>\n",
       "      <td>good</td>\n",
       "      <td>scientist</td>\n",
       "      <td>buy</td>\n",
       "      <td>make</td>\n",
       "      <td>probabl</td>\n",
       "      <td>immigr</td>\n",
       "      <td>give</td>\n",
       "      <td>someon</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>file</td>\n",
       "      <td>neural network</td>\n",
       "      <td>work</td>\n",
       "      <td>cost</td>\n",
       "      <td>make</td>\n",
       "      <td>data</td>\n",
       "      <td>produc</td>\n",
       "      <td>png</td>\n",
       "      <td>point</td>\n",
       "      <td>creat</td>\n",
       "      <td>diet</td>\n",
       "      <td>space</td>\n",
       "      <td>make</td>\n",
       "      <td>work</td>\n",
       "      <td>write</td>\n",
       "      <td>tool</td>\n",
       "      <td>plea</td>\n",
       "      <td>fight</td>\n",
       "      <td>model</td>\n",
       "      <td>human</td>\n",
       "      <td>watch</td>\n",
       "      <td>medic</td>\n",
       "      <td>report</td>\n",
       "      <td>time</td>\n",
       "      <td>govern</td>\n",
       "      <td>presid</td>\n",
       "      <td>minor</td>\n",
       "      <td>mile</td>\n",
       "      <td>ml</td>\n",
       "      <td>year</td>\n",
       "      <td>believ</td>\n",
       "      <td>time</td>\n",
       "      <td>rate</td>\n",
       "      <td>pay</td>\n",
       "      <td>life</td>\n",
       "      <td>model</td>\n",
       "      <td>polic</td>\n",
       "      <td>age</td>\n",
       "      <td>season</td>\n",
       "      <td>place</td>\n",
       "      <td>time</td>\n",
       "      <td>year</td>\n",
       "      <td>tri</td>\n",
       "      <td>ml</td>\n",
       "      <td>power</td>\n",
       "      <td>r</td>\n",
       "      <td>sex</td>\n",
       "      <td>call</td>\n",
       "      <td>peopl</td>\n",
       "      <td>set</td>\n",
       "      <td>idea</td>\n",
       "      <td>time</td>\n",
       "      <td>system</td>\n",
       "      <td>store</td>\n",
       "      <td>experi</td>\n",
       "      <td>bank</td>\n",
       "      <td>show</td>\n",
       "      <td>currentthread</td>\n",
       "      <td>popul</td>\n",
       "      <td>survey</td>\n",
       "      <td>feel</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>import</td>\n",
       "      <td>network</td>\n",
       "      <td>code</td>\n",
       "      <td>buy</td>\n",
       "      <td>actual</td>\n",
       "      <td>facebook</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>c</td>\n",
       "      <td>factor</td>\n",
       "      <td>excel</td>\n",
       "      <td>bodi</td>\n",
       "      <td>airport</td>\n",
       "      <td>problem</td>\n",
       "      <td>month</td>\n",
       "      <td>differ</td>\n",
       "      <td>work</td>\n",
       "      <td>comment</td>\n",
       "      <td>china</td>\n",
       "      <td>sampl</td>\n",
       "      <td>chang</td>\n",
       "      <td>find</td>\n",
       "      <td>caus</td>\n",
       "      <td>polit</td>\n",
       "      <td>chanc</td>\n",
       "      <td>insur</td>\n",
       "      <td>republican</td>\n",
       "      <td>asian</td>\n",
       "      <td>vehicl</td>\n",
       "      <td>field</td>\n",
       "      <td>univer</td>\n",
       "      <td>church</td>\n",
       "      <td>compani</td>\n",
       "      <td>poor</td>\n",
       "      <td>googl</td>\n",
       "      <td>thing</td>\n",
       "      <td>output</td>\n",
       "      <td>murder</td>\n",
       "      <td>live</td>\n",
       "      <td>song</td>\n",
       "      <td>popul</td>\n",
       "      <td>make</td>\n",
       "      <td>popul</td>\n",
       "      <td>understand</td>\n",
       "      <td>good</td>\n",
       "      <td>social</td>\n",
       "      <td>thread</td>\n",
       "      <td>girl</td>\n",
       "      <td>stupid</td>\n",
       "      <td>actual</td>\n",
       "      <td>test</td>\n",
       "      <td>tri</td>\n",
       "      <td>watch</td>\n",
       "      <td>good</td>\n",
       "      <td>cheap</td>\n",
       "      <td>compani</td>\n",
       "      <td>dollar</td>\n",
       "      <td>map</td>\n",
       "      <td>c</td>\n",
       "      <td>canada</td>\n",
       "      <td>make</td>\n",
       "      <td>tri</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c</td>\n",
       "      <td>gener</td>\n",
       "      <td>train</td>\n",
       "      <td>save</td>\n",
       "      <td>someth</td>\n",
       "      <td>websit</td>\n",
       "      <td>coal</td>\n",
       "      <td>imag</td>\n",
       "      <td>gener</td>\n",
       "      <td>make</td>\n",
       "      <td>make</td>\n",
       "      <td>time</td>\n",
       "      <td>year</td>\n",
       "      <td>everi</td>\n",
       "      <td>speak</td>\n",
       "      <td>sql</td>\n",
       "      <td>wikiflair</td>\n",
       "      <td>american</td>\n",
       "      <td>number</td>\n",
       "      <td>planet</td>\n",
       "      <td>cool</td>\n",
       "      <td>die</td>\n",
       "      <td>lie</td>\n",
       "      <td>random</td>\n",
       "      <td>healthcar</td>\n",
       "      <td>candid</td>\n",
       "      <td>group</td>\n",
       "      <td>truck</td>\n",
       "      <td>machin learn</td>\n",
       "      <td>degre</td>\n",
       "      <td>god</td>\n",
       "      <td>money</td>\n",
       "      <td>low</td>\n",
       "      <td>iphon</td>\n",
       "      <td>love</td>\n",
       "      <td>gener</td>\n",
       "      <td>suicid</td>\n",
       "      <td>year</td>\n",
       "      <td>music</td>\n",
       "      <td>map</td>\n",
       "      <td>put</td>\n",
       "      <td>show</td>\n",
       "      <td>find</td>\n",
       "      <td>start</td>\n",
       "      <td>make</td>\n",
       "      <td>user</td>\n",
       "      <td>attract</td>\n",
       "      <td>thing</td>\n",
       "      <td>wrong</td>\n",
       "      <td>dataset</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>type</td>\n",
       "      <td>make</td>\n",
       "      <td>program</td>\n",
       "      <td>peopl</td>\n",
       "      <td>chart</td>\n",
       "      <td>post</td>\n",
       "      <td>peopl</td>\n",
       "      <td>respon</td>\n",
       "      <td>realli</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>function</td>\n",
       "      <td>optim</td>\n",
       "      <td>librari</td>\n",
       "      <td>rent</td>\n",
       "      <td>mani</td>\n",
       "      <td>track</td>\n",
       "      <td>oil</td>\n",
       "      <td>file</td>\n",
       "      <td>level</td>\n",
       "      <td>map</td>\n",
       "      <td>obe</td>\n",
       "      <td>airlin</td>\n",
       "      <td>point</td>\n",
       "      <td>spend</td>\n",
       "      <td>charact</td>\n",
       "      <td>learn</td>\n",
       "      <td>postremov</td>\n",
       "      <td>power</td>\n",
       "      <td>weight</td>\n",
       "      <td>water</td>\n",
       "      <td>youtub</td>\n",
       "      <td>cancer</td>\n",
       "      <td>stori</td>\n",
       "      <td>bet</td>\n",
       "      <td>state</td>\n",
       "      <td>democrat</td>\n",
       "      <td>racism</td>\n",
       "      <td>traffic</td>\n",
       "      <td>scienc</td>\n",
       "      <td>teacher</td>\n",
       "      <td>group</td>\n",
       "      <td>worker</td>\n",
       "      <td>incom</td>\n",
       "      <td>watch</td>\n",
       "      <td>friend</td>\n",
       "      <td>weight</td>\n",
       "      <td>death</td>\n",
       "      <td>life</td>\n",
       "      <td>film</td>\n",
       "      <td>counti</td>\n",
       "      <td>cat</td>\n",
       "      <td>total</td>\n",
       "      <td>work</td>\n",
       "      <td>python</td>\n",
       "      <td>countri</td>\n",
       "      <td>rule</td>\n",
       "      <td>guy</td>\n",
       "      <td>reddit</td>\n",
       "      <td>comment</td>\n",
       "      <td>good</td>\n",
       "      <td>write</td>\n",
       "      <td>win</td>\n",
       "      <td>realli</td>\n",
       "      <td>price</td>\n",
       "      <td>skill</td>\n",
       "      <td>price</td>\n",
       "      <td>visual</td>\n",
       "      <td>originsourc</td>\n",
       "      <td>uk</td>\n",
       "      <td>point</td>\n",
       "      <td>care</td>\n",
       "      <td>profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>return</td>\n",
       "      <td>work</td>\n",
       "      <td>kera</td>\n",
       "      <td>make</td>\n",
       "      <td>work</td>\n",
       "      <td>analyt</td>\n",
       "      <td>cost</td>\n",
       "      <td>googl</td>\n",
       "      <td>effect</td>\n",
       "      <td>tableau</td>\n",
       "      <td>day</td>\n",
       "      <td>speed</td>\n",
       "      <td>start</td>\n",
       "      <td>minut</td>\n",
       "      <td>letter</td>\n",
       "      <td>databas</td>\n",
       "      <td>perform</td>\n",
       "      <td>kill</td>\n",
       "      <td>gener</td>\n",
       "      <td>caus</td>\n",
       "      <td>comment</td>\n",
       "      <td>health</td>\n",
       "      <td>read</td>\n",
       "      <td>odd</td>\n",
       "      <td>fund</td>\n",
       "      <td>polit</td>\n",
       "      <td>cultur</td>\n",
       "      <td>speed</td>\n",
       "      <td>comput</td>\n",
       "      <td>highschool</td>\n",
       "      <td>islam</td>\n",
       "      <td>employ</td>\n",
       "      <td>rich</td>\n",
       "      <td>updat</td>\n",
       "      <td>work</td>\n",
       "      <td>tri</td>\n",
       "      <td>law</td>\n",
       "      <td>marri</td>\n",
       "      <td>charact</td>\n",
       "      <td>lot</td>\n",
       "      <td>head</td>\n",
       "      <td>time</td>\n",
       "      <td>make</td>\n",
       "      <td>understand</td>\n",
       "      <td>polit</td>\n",
       "      <td>vote</td>\n",
       "      <td>date</td>\n",
       "      <td>talk</td>\n",
       "      <td>evid</td>\n",
       "      <td>problem</td>\n",
       "      <td>make</td>\n",
       "      <td>make</td>\n",
       "      <td>lot</td>\n",
       "      <td>eat</td>\n",
       "      <td>interview</td>\n",
       "      <td>gold</td>\n",
       "      <td>point</td>\n",
       "      <td>visual</td>\n",
       "      <td>germani</td>\n",
       "      <td>result</td>\n",
       "      <td>problem</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### showing topics & saving to pickle file ###\n",
    "\n",
    "topics = list()\n",
    "df_topics=pd.DataFrame()\n",
    "\n",
    "for i in range(c.num_topics):\n",
    "    wp = optimal_model.show_topic(i)\n",
    "    topics.append(\", \".join([util.decode_tag(word, c) for word, prop in wp]))\n",
    "    df_topics=pd.concat([df_topics, \n",
    "                         pd.DataFrame([util.decode_tag(word, c) for word, prop in wp], \n",
    "                                      columns=['Topic {}'.format(i+1)])\n",
    "                        ], \n",
    "                        axis=1)\n",
    "\n",
    "df_topics_saving= pd.DataFrame(topics, columns=['top keywords'])\n",
    "df_topics_saving.index=range(1, c.num_topics+1)\n",
    "df_topics_saving.to_csv('{}{}_8_{}_topics.csv'.format(c.directory['save'], \n",
    "                                                      c.project_name, \n",
    "                                                      c.num_topics\n",
    "                                                     ), \n",
    "                   encoding='utf-8', \n",
    "                  )\n",
    "\n",
    "# df_topics.index=range(1, 11)\n",
    "# c.display_df(df_topics.T)\n",
    "# df_topics\n",
    "\n",
    "try:\n",
    "    c.os.remove(c.directory['save']+'{}_db_viz_data_{}.pickle'.format(c.project_name, c.num_topics))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dbfile = open(c.directory['save']+'{}_db_viz_data_{}.pickle'.format(c.project_name, c.num_topics), 'ab')\n",
    "db=dict()\n",
    "\n",
    "db['topic_weights']=optimal_model.show_topics(num_topics=c.num_topics, formatted=False)\n",
    "\n",
    "def str_to_list(txt):\n",
    "    return [term.strip() for term in re.split(',', txt)]\n",
    "\n",
    "def str_to_list_df(df):\n",
    "    return df.apply(str_to_list)\n",
    "\n",
    "data_flat = util.parallelize_df(data_lemmatized, str_to_list_df, c)\n",
    "data_flat = [term for terms in data_flat for term in terms]\n",
    "\n",
    "counter = Counter(data_flat)\n",
    "out = []\n",
    "for i, topic in db['topic_weights']:\n",
    "    for word, weight in topic:\n",
    "        out.append([util.decode_tag(word, c), i , weight, counter[word]])\n",
    "db['topic_hist']=out\n",
    "\n",
    "util.display_df(df_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:21.871834Z",
     "start_time": "2019-05-20T15:39:17.264954Z"
    },
    "code_folding": [
     0,
     2,
     19
    ],
    "papermill": {
     "duration": 224.758932,
     "end_time": "2019-05-20T15:47:38.294910",
     "exception": false,
     "start_time": "2019-05-20T15:43:53.535978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 14 partitions with 14 cores for normalize_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None value = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.319749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154423</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Topic normalization with minimum topic cutoff ###\n",
    "\n",
    "def normalize(row):\n",
    "    try:\n",
    "        # prop=[x[1] if x[1]>c.topic_cutoff_threshold else 0 for x in row]\n",
    "        prop=[]\n",
    "        for item in row:\n",
    "            if item is None:\n",
    "                util.count_sync(1000)\n",
    "                prop.append(0)\n",
    "            else:\n",
    "                prop.append(item[1] if item[1] > c.topic_cutoff_threshold else 0)\n",
    "        # prop = [x[1] if x is not None and x[1] > c.topic_cutoff_threshold else 0 for x in row]\n",
    "        if np.sum(prop)==0:\n",
    "            return pd.Series(prop)\n",
    "        return pd.Series(prop/np.sum(prop), index=range(c.num_topics))\n",
    "    except:\n",
    "        raise ValueError('row = {}'.format(row))\n",
    "\n",
    "def normalize_df(df):\n",
    "    return df.apply(normalize, axis=1)\n",
    "\n",
    "\n",
    "df_optimal_model = pd.DataFrame(optimal_model_corpus)\n",
    "# c.init_parallel(True)\n",
    "# df_optimal_model_normalized=df_optimal_model.parallel_apply(normalize, axis=1)\n",
    "df_optimal_model_normalized=util.parallelize_df(df_optimal_model, normalize_df, c)\n",
    "\n",
    "print('None value = {}'.format(util.counter_sync))\n",
    "util.display_df(df_optimal_model_normalized.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:31.988159Z",
     "start_time": "2019-05-20T15:39:21.874397Z"
    },
    "code_folding": [
     0,
     2,
     10,
     20,
     24,
     29
    ],
    "papermill": {
     "duration": 159.246943,
     "end_time": "2019-05-20T15:50:17.562074",
     "exception": false,
     "start_time": "2019-05-20T15:47:38.315131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pandarallel memory created - Size: 50000 MB\n",
      "Pandarallel will run on 14 workers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Id</th>\n",
       "      <th>Group</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>learn, paper, model, train, algorithm, neural ...</td>\n",
       "      <td>Measuring human performance on standard image ...</td>\n",
       "      <td>2015-01-01 00:29:40</td>\n",
       "      <td>2qzibe</td>\n",
       "      <td>submissions</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>countri, american, europ, world, immigr, popul...</td>\n",
       "      <td>European economy guide: Taking Europes pulse</td>\n",
       "      <td>2015-01-01 03:52:22</td>\n",
       "      <td>2qzv35</td>\n",
       "      <td>submissions</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0.3402</td>\n",
       "      <td>comment, reddit, post, subreddit, link, r, thr...</td>\n",
       "      <td>Popularity of visual forms in DataIsBeautiful ...</td>\n",
       "      <td>2015-01-01 05:23:25</td>\n",
       "      <td>2qzzaa</td>\n",
       "      <td>submissions</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>dog, back, hand, guy, wear, time, make, put, c...</td>\n",
       "      <td>JOE GROOMING - DAILY SHAMPOO ~ best shampoo fo...</td>\n",
       "      <td>2015-01-01 07:16:15</td>\n",
       "      <td>2r048c</td>\n",
       "      <td>submissions</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>temperatur, year, earth, warm, climat, human, ...</td>\n",
       "      <td>Los Angeles Traffic Accident Rate in Rainy vs ...</td>\n",
       "      <td>2015-01-01 10:25:46</td>\n",
       "      <td>2r0e7b</td>\n",
       "      <td>submissions</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>cour, learn, machin learn, book, math, ml, goo...</td>\n",
       "      <td>How did you get good at ML? I feel like practi...</td>\n",
       "      <td>2015-01-01 11:02:17</td>\n",
       "      <td>2r0gu6</td>\n",
       "      <td>submissions</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>number, data, averag, rate, high, year, popul,...</td>\n",
       "      <td>Last year some guy posted how many times he po...</td>\n",
       "      <td>2015-01-01 11:33:15</td>\n",
       "      <td>2r0jax</td>\n",
       "      <td>submissions</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>fuck, peopl, shit, make, guy, call, stupid, th...</td>\n",
       "      <td>How to lie with Visualization: A humorous less...</td>\n",
       "      <td>2015-01-01 12:02:42</td>\n",
       "      <td>2r0lux</td>\n",
       "      <td>submissions</td>\n",
       "      <td>datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>data, python, r, code, languag, tool, work, sq...</td>\n",
       "      <td>Recommended Web Analytics Software? a company ...</td>\n",
       "      <td>2015-01-01 13:21:21</td>\n",
       "      <td>2r0tbc</td>\n",
       "      <td>submissions</td>\n",
       "      <td>analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5760</td>\n",
       "      <td>distribut, function, valu, point, probabl, mod...</td>\n",
       "      <td>Learning Information Geometry I have recently ...</td>\n",
       "      <td>2015-01-01 13:30:09</td>\n",
       "      <td>2r0u4u</td>\n",
       "      <td>submissions</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### find dominant topic for each document ###\n",
    "\n",
    "def find_dominant_topic(row):\n",
    "    row = sorted(enumerate(row), key=lambda x: (x[1]), reverse=True)\n",
    "    topic_num=row[0][0]\n",
    "    prop_topic=row[0][1]\n",
    "    return pd.Series([int(topic_num),\n",
    "                                     round(prop_topic,4), \n",
    "                                     topics[topic_num]]\n",
    "                                   )\n",
    "def find_dominant_topic_df(df):\n",
    "    return df.apply(find_dominant_topic, axis=1)\n",
    "\n",
    "util.init_parallel(True, c)\n",
    "df_topic_sents_keywords = df_optimal_model_normalized.parallel_apply(find_dominant_topic, axis=1)\n",
    "# df_topic_sents_keywords=util.parallelize_df(df_optimal_model_normalized, find_dominant_topic_df, c)\n",
    "\n",
    "col_selected=['txt_orig', 'date', 'id', 'group']\n",
    "col_renamed=['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords', 'Text', 'Date', 'Id', 'Group']\n",
    "\n",
    "if list(c.template['files'].values())[0]['cols']['category'] is not None:\n",
    "    col_selected.append('category')\n",
    "    col_renamed.append('category')\n",
    "    \n",
    "df_topic_sents_keywords = pd.concat([df_topic_sents_keywords, \n",
    "                                            df_text[col_selected]], \n",
    "                                           ignore_index=True, \n",
    "                                           axis=1)\n",
    "\n",
    "util.save_df_to_sql(df_topic_sents_keywords,\n",
    "          '{}{}_sql_docs_dominant_topic.sqlite'.format(c.directory['save'],c.project_name),\n",
    "          'docs'\n",
    "         )\n",
    "\n",
    "df_topic_sents_keywords.columns=col_renamed\n",
    "util.display_df(df_topic_sents_keywords.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:39.747918Z",
     "start_time": "2019-05-20T15:39:31.991645Z"
    },
    "code_folding": [
     0,
     3,
     25,
     38,
     42,
     54
    ],
    "papermill": {
     "duration": 224.683226,
     "end_time": "2019-05-20T15:54:02.259012",
     "exception": false,
     "start_time": "2019-05-20T15:50:17.575786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 14 partitions with 14 cores for find_dominant_topic_for_original_weight_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 number of None in optimal model df!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>all_text</th>\n",
       "      <th>txt_orig</th>\n",
       "      <th>txt_lemmatized</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>Dict iterations are now order-of-assignment?? ...</td>\n",
       "      <td>Dict iterations are now order-of-assignment?? ...</td>\n",
       "      <td>dict, iter, order, assign, think, use, notat, ...</td>\n",
       "      <td>dtedg4n</td>\n",
       "      <td>comments</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>How do I import a large (+TB) csv dataframe in...</td>\n",
       "      <td>How do I import a large (+TB) csv dataframe in...</td>\n",
       "      <td>import, larg, csv, datafram, hdf, object, key,...</td>\n",
       "      <td>56elm6</td>\n",
       "      <td>submissions</td>\n",
       "      <td>bigdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>How to massage this data into a dataframe (e.g...</td>\n",
       "      <td>How to massage this data into a dataframe (e.g...</td>\n",
       "      <td>massag, data, datafram, eg, panda, datafram, f...</td>\n",
       "      <td>4tyio1</td>\n",
       "      <td>submissions</td>\n",
       "      <td>datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>Tensorflow feed_dict Error I have the followin...</td>\n",
       "      <td>Tensorflow feed_dict Error I have the followin...</td>\n",
       "      <td>tensorflow, feeddict, error, follow, code, pri...</td>\n",
       "      <td>81vufz</td>\n",
       "      <td>submissions</td>\n",
       "      <td>learnmachinelearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>How to avoid repetations in the next_batch fun...</td>\n",
       "      <td>How to avoid repetations in the next_batch fun...</td>\n",
       "      <td>avoid, repet, nextbatch, function, tensorflow,...</td>\n",
       "      <td>95x1wh</td>\n",
       "      <td>submissions</td>\n",
       "      <td>MLQuestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>My program. clc; %Gen CWorld and CImage points...</td>\n",
       "      <td>My program. \\nclc; \\n%Gen CWorld and CImage po...</td>\n",
       "      <td>program, clc, gen, cworld, cimag, point, fov, ...</td>\n",
       "      <td>czb4xh2</td>\n",
       "      <td>comments</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>true and if u check the next file ex1.multi I ...</td>\n",
       "      <td>true and if u check the next file ex1.multi I ...</td>\n",
       "      <td>true, u, check, next, file, multi, figur, late...</td>\n",
       "      <td>e1xyrhp</td>\n",
       "      <td>comments</td>\n",
       "      <td>learnmachinelearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>okay, so I just posted the wrong code. I'm sor...</td>\n",
       "      <td>okay, so I just posted the wrong code. I'm sor...</td>\n",
       "      <td>wrong, code, sorri, anoth, question, decod, on...</td>\n",
       "      <td>d7jbjtw</td>\n",
       "      <td>comments</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>You could more simply use the cache function i...</td>\n",
       "      <td>You could more simply use the cache function i...</td>\n",
       "      <td>simpli, cach, function, python, doc, python, o...</td>\n",
       "      <td>dzof8j4</td>\n",
       "      <td>comments</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>So I now have: def makePoint( lon:Double, lat:...</td>\n",
       "      <td>So I now have:\\n\\n    def makePoint( lon:Doubl...</td>\n",
       "      <td>def, makepoint, lon, doubl, lat, doubl, point,...</td>\n",
       "      <td>d5qxz41</td>\n",
       "      <td>comments</td>\n",
       "      <td>datascience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Group top K sentences under each topic from original weights + saving ###\n",
    "\n",
    "\n",
    "def find_dominant_topic_for_original_weight(row):\n",
    "    # c.print_asynch(row[0])\n",
    "    topic_num=row[0][0]\n",
    "    prop_topic=row[0][1]\n",
    "\n",
    "    for item in row[1:]:\n",
    "#         c.print_asynch('item in for {} - {} - {}'.format(item, item[0], item[1]))\n",
    "        if item is None or item[0] is None or item[1] is None:\n",
    "            util.count_sync(1000)\n",
    "        elif item[1]> prop_topic:\n",
    "            topic_num=item[0]\n",
    "            prop_topic=item[1]\n",
    "\n",
    "    # row = sorted(enumerate(row), key=lambda x: (x[1][1] if x[1][1] is not None else 0), reverse=True)\n",
    "    # topic_num=row[0][1][0]\n",
    "    # prop_topic=row[0][1][1]\n",
    "\n",
    "    return pd.Series([int(topic_num),\n",
    "                                     round(prop_topic,4), \n",
    "                                     topics[topic_num]]\n",
    "                                   )\n",
    "\n",
    "def find_dominant_topic_for_original_weight_df(df):\n",
    "    return df.apply(find_dominant_topic_for_original_weight, axis=1)\n",
    "\n",
    "# c.init_parallel(True)\n",
    "# df_optimal_original = df_optimal_model.parallel_apply(find_dominant_topic_for_original_weight, axis=1)\n",
    "df_optimal_original = util.parallelize_df(df_optimal_model, find_dominant_topic_for_original_weight_df, c)\n",
    "\n",
    "util.print_asynch('{} number of None in optimal model df!'.format(util.counter_sync))\n",
    "\n",
    "col_selected=['all_text', 'txt_orig', 'keywords', 'id', 'group']\n",
    "col_renamed=['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords',\n",
    "                                     'all_text', 'txt_orig', 'txt_lemmatized', 'id', 'group']\n",
    "\n",
    "if list(c.template['files'].values())[0]['cols']['category'] is not None:\n",
    "    col_selected.append('category')\n",
    "    col_renamed.append('category')\n",
    "    \n",
    "df_optimal_original = pd.concat([df_optimal_original,\n",
    "                                 df_text[col_selected]],\n",
    "                                ignore_index=True, \n",
    "                                axis=1\n",
    "                               )\n",
    "df_optimal_original.columns=col_renamed\n",
    "sent_topics_outdf_grpd = df_optimal_original.groupby('Dominant_Topic')\n",
    "\n",
    "# sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "\n",
    "sent_topics_sorteddf_mallet=pd.DataFrame()\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet,\n",
    "                                             grp.sort_values(['Perc_Contribution'],\n",
    "                                                             ascending=[0]).head(c.num_sent)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# sent_topics_sorteddf_mallet.drop(['Date'], inplace=True, axis=1)\n",
    "\n",
    "# Format\n",
    "# sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \n",
    "#                                        'all_text', 'txt_orig', 'keywords']\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.to_csv('{}{}_9_top_{}_samples_by_dominant_topics.csv'.format(c.directory['save'], \n",
    "                                                                                         c.project_name,\n",
    "                                                                                         c.num_sent\n",
    "                                                                                        ),\n",
    "                                   index=False)\n",
    "\n",
    "util.display_df(sent_topics_sorteddf_mallet.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:42.565046Z",
     "start_time": "2019-05-20T15:39:42.516427Z"
    },
    "code_folding": [
     0,
     11
    ],
    "papermill": {
     "duration": 0.911469,
     "end_time": "2019-05-20T15:54:03.217524",
     "exception": false,
     "start_time": "2019-05-20T15:54:02.306055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>8190</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>learn, paper, model, train, algorithm, neural ...</td>\n",
       "      <td>28665</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gpu, tensorflow, run, model, comput, work, cod...</td>\n",
       "      <td>31255</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>pay, money, hous, year, live, cost, buy, save,...</td>\n",
       "      <td>40608</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>peopl, thing, realli, lot, good, make, actual,...</td>\n",
       "      <td>51134</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>googl, page, site, user, search, data, faceboo...</td>\n",
       "      <td>41271</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>energi, water, power, build, electr, produc, n...</td>\n",
       "      <td>26645</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>www, org, html, pdf, jpg, png, c, imag, file, ...</td>\n",
       "      <td>17058</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>differ, group, thing, correl, peopl, point, fa...</td>\n",
       "      <td>20568</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>data, sourc, tool, visual, www, creat, excel, ...</td>\n",
       "      <td>29012</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>eat, food, fat, calori, weight, diet, bodi, ma...</td>\n",
       "      <td>22507</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>flight, plane, fli, ship, travel, space, airpo...</td>\n",
       "      <td>12246</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>time, peopl, thing, happen, chang, make, probl...</td>\n",
       "      <td>35379</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>day, time, hour, year, week, work, month, ever...</td>\n",
       "      <td>45777</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>word, languag, text, english, sentenc, write, ...</td>\n",
       "      <td>22021</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>data, python, r, code, languag, tool, work, sq...</td>\n",
       "      <td>35329</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>wiki, index, visual, data, post, plea, comment...</td>\n",
       "      <td>30422</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>war, militari, countri, world, russia, fight, ...</td>\n",
       "      <td>38141</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>distribut, function, valu, point, probabl, mod...</td>\n",
       "      <td>24489</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>temperatur, year, earth, warm, climat, human, ...</td>\n",
       "      <td>30998</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>video, post, realli, interest, make, watch, fi...</td>\n",
       "      <td>39625</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>drug, peopl, smoke, vaccin, doctor, medic, cau...</td>\n",
       "      <td>29498</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>news, trump, articl, sourc, medium, report, po...</td>\n",
       "      <td>29218</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>game, win, play, move, number, time, chanc, ra...</td>\n",
       "      <td>13723</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>pay, tax, money, cost, spend, govern, insur, h...</td>\n",
       "      <td>38241</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>vote, state, elect, trump, parti, presid, repu...</td>\n",
       "      <td>64479</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>white, black, peopl, race, racist, minor, asia...</td>\n",
       "      <td>17027</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>car, drive, road, driver, time, mile, vehicl, ...</td>\n",
       "      <td>27733</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>research, ai, paper, human, work, ml, field, m...</td>\n",
       "      <td>30044</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>school, student, colleg, educ, class, year, un...</td>\n",
       "      <td>33396</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>peopl, religion, muslim, christian, religi, be...</td>\n",
       "      <td>24659</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>work, job, peopl, pay, make, time, compani, mo...</td>\n",
       "      <td>41615</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>peopl, countri, high, popul, world, rate, poor...</td>\n",
       "      <td>31543</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>phone, internet, appl, app, netflix, pay, goog...</td>\n",
       "      <td>41312</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>feel, time, realli, make, good, life, thing, l...</td>\n",
       "      <td>51265</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>imag, train, layer, network, input, model, out...</td>\n",
       "      <td>41194</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>gun, peopl, kill, shoot, crime, polic, murder,...</td>\n",
       "      <td>40052</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>kid, child, parent, peopl, famili, age, live, ...</td>\n",
       "      <td>30343</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>movi, show, episod, watch, good, season, song,...</td>\n",
       "      <td>64009</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>citi, live, state, area, peopl, place, popul, ...</td>\n",
       "      <td>82490</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>dog, back, hand, guy, wear, time, make, put, c...</td>\n",
       "      <td>50071</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>number, data, averag, rate, high, year, popul,...</td>\n",
       "      <td>48984</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>read, someth, good, start, point, tri, underst...</td>\n",
       "      <td>22761</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>cour, learn, machin learn, book, math, ml, goo...</td>\n",
       "      <td>35558</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>govern, peopl, state, law, system, power, soci...</td>\n",
       "      <td>43205</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>comment, reddit, post, subreddit, link, r, thr...</td>\n",
       "      <td>28858</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>woman, man, male, femal, gender, sex, girl, at...</td>\n",
       "      <td>37028</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>fuck, peopl, shit, make, guy, call, stupid, th...</td>\n",
       "      <td>73745</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>make, point, fact, argument, claim, peopl, act...</td>\n",
       "      <td>56644</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>model, data, train, predict, featur, set, test...</td>\n",
       "      <td>37173</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>project, work, code, interest, find, idea, tri...</td>\n",
       "      <td>28340</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>game, play, team, sport, player, time, watch, ...</td>\n",
       "      <td>43023</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>problem, time, work, thing, make, system, good...</td>\n",
       "      <td>21050</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>drink, buy, beer, food, good, store, cheap, ma...</td>\n",
       "      <td>34667</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>data, job, work, data scienc, scientist, exper...</td>\n",
       "      <td>59570</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>bitcoin, money, valu, currenc, buy, bank, doll...</td>\n",
       "      <td>15201</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>data, graph, color, line, make, show, map, cha...</td>\n",
       "      <td>62563</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>imag, link, tri, index, probabl, currentthread...</td>\n",
       "      <td>10240</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>countri, american, europ, world, immigr, popul...</td>\n",
       "      <td>53062</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>data, question, answer, inform, give, survey, ...</td>\n",
       "      <td>23201</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>peopl, make, person, thing, someon, feel, tri,...</td>\n",
       "      <td>43214</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>compani, market, product, busi, make, money, p...</td>\n",
       "      <td>34318</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Number of Documents for Each Topic - original ###\n",
    "\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = np.round(100 * topic_counts/topic_counts.sum(), 2)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([\n",
    "    pd.Series(range(1, c.num_topics+1)), \n",
    "    pd.Series(topics), \n",
    "    topic_counts, \n",
    "    topic_contribution\n",
    "], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Topic_Num', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "df_dominant_topics.to_csv('{}{}_10_dominant_topics_dist_original.csv'.format(c.directory['save'], \n",
    "                                                                            c.project_name\n",
    "                                                                           ),\n",
    "                         index=False)\n",
    "# Show\n",
    "util.display_df(df_dominant_topics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:43.278605Z",
     "start_time": "2019-05-20T15:39:43.250247Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 0.604456,
     "end_time": "2019-05-20T15:54:03.845113",
     "exception": false,
     "start_time": "2019-05-20T15:54:03.240657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Weight_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data, valu, column, cluster, code, file, impor...</td>\n",
       "      <td>7209.359679</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>learn, paper, model, train, algorithm, neural ...</td>\n",
       "      <td>26789.270539</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gpu, tensorflow, run, model, comput, work, cod...</td>\n",
       "      <td>29168.288276</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>pay, money, hous, year, live, cost, buy, save,...</td>\n",
       "      <td>38871.378446</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>peopl, thing, realli, lot, good, make, actual,...</td>\n",
       "      <td>67528.214137</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>googl, page, site, user, search, data, faceboo...</td>\n",
       "      <td>39974.193409</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>energi, water, power, build, electr, produc, n...</td>\n",
       "      <td>24896.486930</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>www, org, html, pdf, jpg, png, c, imag, file, ...</td>\n",
       "      <td>18800.892482</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>differ, group, thing, correl, peopl, point, fa...</td>\n",
       "      <td>25158.948276</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>data, sourc, tool, visual, www, creat, excel, ...</td>\n",
       "      <td>27358.690989</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>eat, food, fat, calori, weight, diet, bodi, ma...</td>\n",
       "      <td>21129.720878</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>flight, plane, fli, ship, travel, space, airpo...</td>\n",
       "      <td>11846.891107</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>time, peopl, thing, happen, chang, make, probl...</td>\n",
       "      <td>44703.028995</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>day, time, hour, year, week, work, month, ever...</td>\n",
       "      <td>48917.372276</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>word, languag, text, english, sentenc, write, ...</td>\n",
       "      <td>21893.085050</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>data, python, r, code, languag, tool, work, sq...</td>\n",
       "      <td>33265.116201</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>wiki, index, visual, data, post, plea, comment...</td>\n",
       "      <td>30672.190535</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>war, militari, countri, world, russia, fight, ...</td>\n",
       "      <td>35737.320244</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>distribut, function, valu, point, probabl, mod...</td>\n",
       "      <td>23703.742262</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>temperatur, year, earth, warm, climat, human, ...</td>\n",
       "      <td>29208.462048</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>video, post, realli, interest, make, watch, fi...</td>\n",
       "      <td>40819.027158</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>drug, peopl, smoke, vaccin, doctor, medic, cau...</td>\n",
       "      <td>28183.365148</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>news, trump, articl, sourc, medium, report, po...</td>\n",
       "      <td>28810.430321</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>game, win, play, move, number, time, chanc, ra...</td>\n",
       "      <td>13399.683863</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>pay, tax, money, cost, spend, govern, insur, h...</td>\n",
       "      <td>36011.442246</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>vote, state, elect, trump, parti, presid, repu...</td>\n",
       "      <td>58948.867698</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>white, black, peopl, race, racist, minor, asia...</td>\n",
       "      <td>16897.253923</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>car, drive, road, driver, time, mile, vehicl, ...</td>\n",
       "      <td>26159.601704</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>research, ai, paper, human, work, ml, field, m...</td>\n",
       "      <td>29140.759442</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>school, student, colleg, educ, class, year, un...</td>\n",
       "      <td>32648.436551</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>peopl, religion, muslim, christian, religi, be...</td>\n",
       "      <td>23108.871331</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>work, job, peopl, pay, make, time, compani, mo...</td>\n",
       "      <td>40365.869549</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>peopl, countri, high, popul, world, rate, poor...</td>\n",
       "      <td>31378.945893</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>phone, internet, appl, app, netflix, pay, goog...</td>\n",
       "      <td>38503.755052</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>feel, time, realli, make, good, life, thing, l...</td>\n",
       "      <td>56014.975570</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>imag, train, layer, network, input, model, out...</td>\n",
       "      <td>38224.519944</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>gun, peopl, kill, shoot, crime, polic, murder,...</td>\n",
       "      <td>37045.380597</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>kid, child, parent, peopl, famili, age, live, ...</td>\n",
       "      <td>30672.576207</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>movi, show, episod, watch, good, season, song,...</td>\n",
       "      <td>59603.703805</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>citi, live, state, area, peopl, place, popul, ...</td>\n",
       "      <td>79597.077319</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>dog, back, hand, guy, wear, time, make, put, c...</td>\n",
       "      <td>49612.968581</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>number, data, averag, rate, high, year, popul,...</td>\n",
       "      <td>54526.950899</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>read, someth, good, start, point, tri, underst...</td>\n",
       "      <td>27034.452396</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>cour, learn, machin learn, book, math, ml, goo...</td>\n",
       "      <td>34302.342733</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>govern, peopl, state, law, system, power, soci...</td>\n",
       "      <td>42404.492311</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>comment, reddit, post, subreddit, link, r, thr...</td>\n",
       "      <td>28242.958696</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>woman, man, male, femal, gender, sex, girl, at...</td>\n",
       "      <td>35120.748392</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>fuck, peopl, shit, make, guy, call, stupid, th...</td>\n",
       "      <td>77275.521011</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>make, point, fact, argument, claim, peopl, act...</td>\n",
       "      <td>59779.821060</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>model, data, train, predict, featur, set, test...</td>\n",
       "      <td>35542.304236</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>project, work, code, interest, find, idea, tri...</td>\n",
       "      <td>28677.554459</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>game, play, team, sport, player, time, watch, ...</td>\n",
       "      <td>39833.149640</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>problem, time, work, thing, make, system, good...</td>\n",
       "      <td>24479.404799</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>drink, buy, beer, food, good, store, cheap, ma...</td>\n",
       "      <td>33030.840581</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>data, job, work, data scienc, scientist, exper...</td>\n",
       "      <td>55090.603047</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>bitcoin, money, valu, currenc, buy, bank, doll...</td>\n",
       "      <td>14259.164728</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>data, graph, color, line, make, show, map, cha...</td>\n",
       "      <td>61111.759167</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>imag, link, tri, index, probabl, currentthread...</td>\n",
       "      <td>10767.949640</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>countri, american, europ, world, immigr, popul...</td>\n",
       "      <td>53353.750254</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>data, question, answer, inform, give, survey, ...</td>\n",
       "      <td>25743.704794</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>peopl, make, person, thing, someon, feel, tri,...</td>\n",
       "      <td>47740.308619</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>compani, market, product, busi, make, money, p...</td>\n",
       "      <td>34580.053877</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Number of Documents for Each Topic - normalized ###\n",
    "\n",
    "topic_weights=df_optimal_model_normalized.apply(lambda col: np.sum(col), axis=0)\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = np.round(100 * pd.DataFrame(topic_weights/np.sum(topic_weights)), 2)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics_cleaned = pd.concat([pd.Series(range(1, c.num_topics+1)), \n",
    "                                       pd.Series(topics), \n",
    "                                       pd.DataFrame(topic_weights), \n",
    "                                       topic_contribution\n",
    "                                      ], \n",
    "                                      axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics_cleaned.columns = ['Topic_Num', 'Topic_Keywords', 'Weight_Documents', 'Perc_Documents']\n",
    "df_dominant_topics_cleaned.to_csv('{}{}_10_dominant_topics_dist_normalized.csv'.format(c.directory['save'], \n",
    "                                                                            c.project_name\n",
    "                                                                           ),\n",
    "                         index=False)\n",
    "\n",
    "# Show\n",
    "util.display_df(df_dominant_topics_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:44.013776Z",
     "start_time": "2019-05-20T15:39:43.856920Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 48.535613,
     "end_time": "2019-05-20T15:54:52.398390",
     "exception": false,
     "start_time": "2019-05-20T15:54:03.862777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Number of points to be disaplyed = 37185'\n"
     ]
    }
   ],
   "source": [
    "### removing docs less than the threshold for visualiztion ###\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "# for i, row_list in enumerate(lda_model[corpus]):\n",
    "#     topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# for i, row_list in enumerate(optimal_model[corpus]):\n",
    "for i, row_list in enumerate(optimal_model_corpus):\n",
    "    topic_weights.append([w for i, w in row_list])\n",
    "    \n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "idx = np.amax(arr, axis=1) > c.TSNE_threshold\n",
    "df_text_TSNE =df_text[idx]\n",
    "arr = arr[idx]\n",
    "util.pprint('Number of points to be disaplyed = {}'.format(len(arr)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:47.513764Z",
     "start_time": "2019-05-20T15:39:46.714068Z"
    },
    "code_folding": [
     0
    ],
    "papermill": {
     "duration": 215.097684,
     "end_time": "2019-05-20T15:58:27.519415",
     "exception": false,
     "start_time": "2019-05-20T15:54:52.421731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 37185 samples in 0.109s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 37185 samples in 25.298s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 2000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 7000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 13000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 19000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 27000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 28000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 29000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 30000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 31000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 32000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 33000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 34000 / 37185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed conditional probabilities for sample 35000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 36000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 37000 / 37185\n",
      "[t-SNE] Computed conditional probabilities for sample 37185 / 37185\n",
      "[t-SNE] Mean sigma: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 69.636879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] KL divergence after 1000 iterations: 1.003152\n"
     ]
    }
   ],
   "source": [
    "### TSNE dimensionality reduction ###\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2,\n",
    "                  verbose=1, \n",
    "                  random_state=0, \n",
    "                  angle=.99, \n",
    "                  init='pca'\n",
    "                 )\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "db['tsne_lda'] = tsne_lda\n",
    "db['df_text_TSNE'] = df_text_TSNE\n",
    "db['arr'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T15:39:55.429211Z",
     "start_time": "2019-05-20T15:39:49.721436Z"
    },
    "code_folding": [
     2,
     5,
     16
    ],
    "papermill": {
     "duration": 162.212741,
     "end_time": "2019-05-20T16:01:09.753853",
     "exception": false,
     "start_time": "2019-05-20T15:58:27.541112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 14 partitions with 14 cores for str_date_to_date_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel: 14 partitions with 14 cores for str_date_to_date_df\n"
     ]
    }
   ],
   "source": [
    "### collecting data for temporal graphs ###\n",
    "\n",
    "def timestamp_to_date(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp)\n",
    "\n",
    "def timestamp_to_date_df(df):\n",
    "    return df.apply(timestamp_to_date)\n",
    "\n",
    "def str_date_to_date(date):\n",
    "    try:\n",
    "#         return pd.to_datetime(df_text['date'], format=c.template['files'][df_name]['formats']['date'])\n",
    "        return pd.to_datetime(date)\n",
    "    except ValueError as e:\n",
    "        util.print_asynch(date)\n",
    "        raise Failed('Had issue processing {} \\n {}'.format(date, e))\n",
    "\n",
    "def str_date_to_date_df(df):\n",
    "    return df.apply(str_date_to_date)\n",
    "\n",
    "\n",
    "### temporal graph data - count ###\n",
    "\n",
    "df_name='Count'\n",
    "df_dominant_topic_date = df_topic_sents_keywords[['Dominant_Topic', 'Date']]\n",
    "\n",
    "# c.init_parallel(False)\n",
    "# date = c.pd.DataFrame(df_dominant_topic_date['Date'].parallel_apply(timestamp_to_date), \n",
    "# date = pd.DataFrame(util.parallelize_df(df_dominant_topic_date['Date'], timestamp_to_date_df, c), columns=['Date'])\n",
    "date = pd.DataFrame(util.parallelize_df(df_dominant_topic_date['Date'], str_date_to_date_df, c), columns=['Date'])\n",
    "\n",
    "df_topic_date = pd.concat([date,df_dominant_topic_date['Dominant_Topic']],axis=1)\n",
    "df_topic_date.index=df_topic_date['Date']\n",
    "\n",
    "\n",
    "### temporal graph data - proportion ###\n",
    "\n",
    "df_name='Proportion'\n",
    "df_doc_topic_weight = pd.concat([df_optimal_model_normalized, pd.DataFrame(df_text['date'])], axis=1)\n",
    "\n",
    "# util.init_parallel(False)\n",
    "# df_doc_topic_weight['Date'] = df_topic_sents_keywords['Date'].parallel_apply(timestamp_to_date)\n",
    "# df_doc_topic_weight['Date'] = util.parallelize_df(df_topic_sents_keywords['Date'], timestamp_to_date_df, c)\n",
    "df_doc_topic_weight['Date'] = util.parallelize_df(df_topic_sents_keywords['Date'], str_date_to_date_df, c)\n",
    "df_doc_topic_weight.index=df_doc_topic_weight['Date']\n",
    "\n",
    "df_name='Count'\n",
    "dfs_trend=dict()\n",
    "for freq in ['D', 'W', 'M']:\n",
    "    dfs_trend[df_name]=pd.DataFrame(columns=['Date', \n",
    "                                               df_name, \n",
    "                                               'Topic'\n",
    "                                              ])\n",
    "    for i in range(c.num_topics):\n",
    "        df_topic = df_topic_date.loc[df_topic_date['Dominant_Topic']==i]\n",
    "        g=df_topic.groupby(pd.Grouper(freq=freq))\n",
    "        result = g.count()['Date']\n",
    "        result = pd.DataFrame({'Date': result.index, df_name: result.values, 'Topic':i})    \n",
    "        dfs_trend[df_name] = pd.concat([dfs_trend[df_name], result], axis=0, sort=True)\n",
    "    \n",
    "    db['{}-{}'.format(df_name, freq)]=dfs_trend[df_name]\n",
    "\n",
    "df_name='Proportion'\n",
    "\n",
    "for freq in ['D', 'W', 'M']:\n",
    "    dfs_trend[df_name]=pd.DataFrame(columns=['Date',\n",
    "                                               df_name, \n",
    "                                               'Topic'\n",
    "                                              ])\n",
    "    for i in range(c.num_topics):\n",
    "        df_topic = df_doc_topic_weight[i]\n",
    "        g=df_topic.groupby(pd.Grouper(freq=freq))\n",
    "        result = g.sum()/g.count()\n",
    "#         result = g.sum()\n",
    "        result = pd.DataFrame({'Date': result.index, df_name: result.values, 'Topic':i})    \n",
    "        dfs_trend[df_name] = pd.concat([dfs_trend[df_name], result], sort=True)\n",
    "    db['{}-{}'.format(df_name, freq)]=dfs_trend[df_name]\n",
    "\n",
    "pickle.dump(db, dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01713,
     "end_time": "2019-05-20T16:01:09.792004",
     "exception": false,
     "start_time": "2019-05-20T16:01:09.774874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 1177.622125,
   "end_time": "2019-05-20T16:01:17.700348",
   "environment_variables": {},
   "exception": null,
   "input_path": "LDA_6_Viz_Computation.ipynb",
   "output_path": "/scratch/hkarbasi/LDA/Reddit/LDA_6_Viz_Computation_0_Reddit_NODE077.ipynb",
   "parameters": {
    "config": "configs.config_Reddit",
    "mem": 700000,
    "num_cores": 14
   },
   "start_time": "2019-05-20T15:41:40.078223",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}